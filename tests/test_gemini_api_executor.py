"""
Gemini API æ‰§è¡Œå™¨å•å…ƒæµ‹è¯•

æµ‹è¯• GeminiAPIExecutor çš„å…·ä½“å®ç°ï¼ŒåŒ…æ‹¬æ¶ˆæ¯æ ¼å¼åŒ–ã€API è°ƒç”¨å’Œé”™è¯¯å¤„ç†ã€‚
"""
import pytest
from unittest.mock import Mock, patch, MagicMock
from feishu_bot.gemini_api_executor import GeminiAPIExecutor
from feishu_bot.models import ExecutionResult, Message


def test_gemini_executor_initialization():
    """æµ‹è¯• Gemini æ‰§è¡Œå™¨çš„åˆå§‹åŒ–"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel') as mock_model:
            executor = GeminiAPIExecutor(
                api_key="test_key",
                model="gemini-1.5-pro",
                timeout=30
            )
            
            assert executor.api_key == "test_key"
            assert executor.model == "gemini-1.5-pro"
            assert executor.timeout == 30
            assert executor.client is not None


def test_gemini_executor_default_model():
    """æµ‹è¯• Gemini æ‰§è¡Œå™¨çš„é»˜è®¤æ¨¡å‹"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="test_key")
            
            assert executor.model == "gemini-2.0-flash-exp"
            assert executor.timeout == 60


def test_get_provider_name():
    """æµ‹è¯• get_provider_name æ–¹æ³•"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="test_key")
            assert executor.get_provider_name() == "gemini-api"


def test_format_messages_without_history():
    """æµ‹è¯•ä¸å¸¦å¯¹è¯å†å²çš„æ¶ˆæ¯æ ¼å¼åŒ–"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="test_key")
            messages = executor.format_messages("Hello Gemini")
            
            assert len(messages) == 1
            assert messages[0]["role"] == "user"
            assert messages[0]["parts"] == ["Hello Gemini"]


def test_format_messages_with_history():
    """æµ‹è¯•å¸¦å¯¹è¯å†å²çš„æ¶ˆæ¯æ ¼å¼åŒ–"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="test_key")
            history = [
                Message(role="user", content="What is Python?", timestamp=1000),
                Message(role="assistant", content="Python is a programming language.", timestamp=1001),
                Message(role="user", content="Tell me more", timestamp=1002),
                Message(role="assistant", content="Python is versatile and easy to learn.", timestamp=1003),
            ]
            
            messages = executor.format_messages("What about its history?", history)
            
            assert len(messages) == 5
            assert messages[0]["role"] == "user"
            assert messages[0]["parts"] == ["What is Python?"]
            assert messages[1]["role"] == "model"  # assistant -> model
            assert messages[1]["parts"] == ["Python is a programming language."]
            assert messages[2]["role"] == "user"
            assert messages[2]["parts"] == ["Tell me more"]
            assert messages[3]["role"] == "model"  # assistant -> model
            assert messages[3]["parts"] == ["Python is versatile and easy to learn."]
            assert messages[4]["role"] == "user"
            assert messages[4]["parts"] == ["What about its history?"]


def test_format_messages_converts_assistant_to_model():
    """æµ‹è¯•æ¶ˆæ¯æ ¼å¼åŒ–æ—¶å°† assistant è§’è‰²è½¬æ¢ä¸º model"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="test_key")
            history = [
                Message(role="assistant", content="I am an assistant", timestamp=1000),
            ]
            
            messages = executor.format_messages("Hello", history)
            
            # éªŒè¯ assistant è¢«è½¬æ¢ä¸º model
            assert messages[0]["role"] == "model"
            assert messages[0]["parts"] == ["I am an assistant"]


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_success_without_history(mock_model_class, mock_configure):
    """æµ‹è¯•æˆåŠŸçš„ API è°ƒç”¨ï¼ˆæ— å¯¹è¯å†å²ï¼‰"""
    # æ¨¡æ‹Ÿ API å“åº”
    mock_model = Mock()
    mock_response = Mock()
    mock_response.text = "This is Gemini's response"
    mock_model.generate_content.return_value = mock_response
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    result = executor.execute("Hello Gemini")
    
    assert result.success is True
    assert result.stdout == "This is Gemini's response"
    assert result.stderr == ""
    assert result.error_message is None
    assert result.execution_time > 0


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_success_with_history(mock_model_class, mock_configure):
    """æµ‹è¯•æˆåŠŸçš„ API è°ƒç”¨ï¼ˆå¸¦å¯¹è¯å†å²ï¼Œä½¿ç”¨ chat æ¨¡å¼ï¼‰"""
    # æ¨¡æ‹Ÿ chat æ¨¡å¼
    mock_model = Mock()
    mock_chat = Mock()
    mock_response = Mock()
    mock_response.text = "Response with context"
    mock_chat.send_message.return_value = mock_response
    mock_model.start_chat.return_value = mock_chat
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    history = [
        Message(role="user", content="Previous question", timestamp=1000),
        Message(role="assistant", content="Previous answer", timestamp=1001),
    ]
    
    result = executor.execute("Follow-up question", conversation_history=history)
    
    assert result.success is True
    assert result.stdout == "Response with context"
    
    # éªŒè¯ä½¿ç”¨äº† chat æ¨¡å¼
    mock_model.start_chat.assert_called_once()
    call_args = mock_model.start_chat.call_args
    history_arg = call_args[1]["history"]
    assert len(history_arg) == 2
    assert history_arg[0]["role"] == "user"
    assert history_arg[0]["parts"] == ["Previous question"]
    assert history_arg[1]["role"] == "model"  # assistant -> model
    assert history_arg[1]["parts"] == ["Previous answer"]
    
    # éªŒè¯å‘é€äº†å½“å‰æ¶ˆæ¯
    mock_chat.send_message.assert_called_once_with(
        "Follow-up question",
        generation_config=None
    )


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_with_additional_params(mock_model_class, mock_configure):
    """æµ‹è¯•å¸¦é¢å¤–å‚æ•°çš„ API è°ƒç”¨"""
    mock_model = Mock()
    mock_response = Mock()
    mock_response.text = "Response"
    mock_model.generate_content.return_value = mock_response
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    params = {
        "temperature": 0.7,
        "max_tokens": 2000,
    }
    
    result = executor.execute("Test prompt", additional_params=params)
    
    assert result.success is True
    
    # éªŒè¯è°ƒç”¨å‚æ•°åŒ…å«é¢å¤–å‚æ•°
    call_args = mock_model.generate_content.call_args
    generation_config = call_args[1]["generation_config"]
    assert generation_config["temperature"] == 0.7
    assert generation_config["max_output_tokens"] == 2000


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_with_history_and_params(mock_model_class, mock_configure):
    """æµ‹è¯•å¸¦å¯¹è¯å†å²å’Œé¢å¤–å‚æ•°çš„ API è°ƒç”¨"""
    mock_model = Mock()
    mock_chat = Mock()
    mock_response = Mock()
    mock_response.text = "Response"
    mock_chat.send_message.return_value = mock_response
    mock_model.start_chat.return_value = mock_chat
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    history = [
        Message(role="user", content="Previous", timestamp=1000),
    ]
    params = {
        "temperature": 0.5,
    }
    
    result = executor.execute("Test", conversation_history=history, additional_params=params)
    
    assert result.success is True
    
    # éªŒè¯ chat æ¨¡å¼ä½¿ç”¨äº†é¢å¤–å‚æ•°
    call_args = mock_chat.send_message.call_args
    generation_config = call_args[1]["generation_config"]
    assert generation_config["temperature"] == 0.5


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_api_error(mock_model_class, mock_configure):
    """æµ‹è¯• API é”™è¯¯å¤„ç†"""
    mock_model = Mock()
    mock_model.generate_content.side_effect = Exception("API quota exceeded")
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    result = executor.execute("Test prompt")
    
    assert result.success is False
    assert result.stdout == ""
    assert "API quota exceeded" in result.stderr
    assert "Gemini API error" in result.error_message
    assert result.execution_time == 0


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_unexpected_error(mock_model_class, mock_configure):
    """æµ‹è¯•æ„å¤–é”™è¯¯å¤„ç†"""
    mock_model = Mock()
    mock_model.generate_content.side_effect = Exception("Unexpected error")
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    result = executor.execute("Test prompt")
    
    assert result.success is False
    assert result.stdout == ""
    assert "Unexpected error" in result.stderr
    assert "Gemini API error" in result.error_message
    assert result.execution_time == 0


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_chat_mode_error(mock_model_class, mock_configure):
    """æµ‹è¯• chat æ¨¡å¼ä¸‹çš„é”™è¯¯å¤„ç†"""
    mock_model = Mock()
    mock_chat = Mock()
    mock_chat.send_message.side_effect = Exception("Chat error")
    mock_model.start_chat.return_value = mock_chat
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    history = [
        Message(role="user", content="Previous", timestamp=1000),
    ]
    
    result = executor.execute("Test", conversation_history=history)
    
    assert result.success is False
    assert "Chat error" in result.stderr
    assert "Gemini API error" in result.error_message


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_uses_correct_model(mock_model_class, mock_configure):
    """æµ‹è¯•ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹"""
    mock_model = Mock()
    mock_response = Mock()
    mock_response.text = "Response"
    mock_model.generate_content.return_value = mock_response
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key", model="gemini-1.5-pro")
    result = executor.execute("Test prompt")
    
    assert result.success is True
    
    # éªŒè¯ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹ï¼ˆåœ¨åˆå§‹åŒ–æ—¶ä¼ é€’ï¼‰
    mock_model_class.assert_called_with("gemini-1.5-pro")


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_without_generation_config_when_no_params(mock_model_class, mock_configure):
    """æµ‹è¯•æ²¡æœ‰é¢å¤–å‚æ•°æ—¶ä¸ä¼ é€’ generation_config"""
    mock_model = Mock()
    mock_response = Mock()
    mock_response.text = "Response"
    mock_model.generate_content.return_value = mock_response
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    result = executor.execute("Test prompt")
    
    assert result.success is True
    
    # éªŒè¯æ²¡æœ‰ä¼ é€’ generation_configï¼ˆæˆ–ä¸º Noneï¼‰
    call_args = mock_model.generate_content.call_args
    generation_config = call_args[1].get("generation_config")
    assert generation_config is None


def test_api_key_configuration():
    """æµ‹è¯• API å¯†é’¥é…ç½®"""
    with patch('feishu_bot.gemini_api_executor.genai.configure') as mock_configure:
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="my_test_key")
            
            # éªŒè¯ genai.configure è¢«è°ƒç”¨å¹¶ä¼ å…¥äº†æ­£ç¡®çš„ API å¯†é’¥
            mock_configure.assert_called_once_with(api_key="my_test_key")


def test_format_messages_with_empty_history():
    """æµ‹è¯•ç©ºå¯¹è¯å†å²çš„æ¶ˆæ¯æ ¼å¼åŒ–"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="test_key")
            messages = executor.format_messages("Hello", conversation_history=[])
            
            # ç©ºå†å²åº”è¯¥åªåŒ…å«å½“å‰æ¶ˆæ¯
            assert len(messages) == 1
            assert messages[0]["role"] == "user"
            assert messages[0]["parts"] == ["Hello"]


def test_format_messages_with_special_characters():
    """æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ¶ˆæ¯æ ¼å¼åŒ–"""
    with patch('feishu_bot.gemini_api_executor.genai.configure'):
        with patch('feishu_bot.gemini_api_executor.genai.GenerativeModel'):
            executor = GeminiAPIExecutor(api_key="test_key")
            special_text = "Hello\n\nThis has:\n- Special chars: @#$%\n- Emojis: ğŸ˜€ğŸ‰\n- Unicode: ä½ å¥½ä¸–ç•Œ"
            messages = executor.format_messages(special_text)
            
            assert len(messages) == 1
            assert messages[0]["parts"] == [special_text]


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_with_empty_response(mock_model_class, mock_configure):
    """æµ‹è¯• API è¿”å›ç©ºå“åº”çš„æƒ…å†µ"""
    mock_model = Mock()
    mock_response = Mock()
    mock_response.text = ""
    mock_model.generate_content.return_value = mock_response
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    result = executor.execute("Test prompt")
    
    assert result.success is True
    assert result.stdout == ""
    assert result.error_message is None


@patch('feishu_bot.gemini_api_executor.genai.configure')
@patch('feishu_bot.gemini_api_executor.genai.GenerativeModel')
def test_execute_with_long_conversation_history(mock_model_class, mock_configure):
    """æµ‹è¯•é•¿å¯¹è¯å†å²çš„å¤„ç†"""
    mock_model = Mock()
    mock_chat = Mock()
    mock_response = Mock()
    mock_response.text = "Response"
    mock_chat.send_message.return_value = mock_response
    mock_model.start_chat.return_value = mock_chat
    mock_model_class.return_value = mock_model
    
    executor = GeminiAPIExecutor(api_key="test_key")
    
    # åˆ›å»ºä¸€ä¸ªåŒ…å« 20 è½®å¯¹è¯çš„å†å²
    history = []
    for i in range(20):
        history.append(Message(role="user", content=f"Question {i}", timestamp=1000 + i * 2))
        history.append(Message(role="assistant", content=f"Answer {i}", timestamp=1001 + i * 2))
    
    result = executor.execute("Final question", conversation_history=history)
    
    assert result.success is True
    
    # éªŒè¯æ‰€æœ‰å†å²æ¶ˆæ¯éƒ½è¢«åŒ…å«
    call_args = mock_model.start_chat.call_args
    history_arg = call_args[1]["history"]
    assert len(history_arg) == 40  # 20 * 2
